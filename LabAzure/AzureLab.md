# Отчет. Лабораторная работа №1. Анализ биллинга облачных сервисов

**Авторство: Цырульников Артём Алексеевич К3239**

## Вариант 10

### Описание работы

На этот раз у нас есть кусочек данных от Azure, и мы хотим навести там порядок. В общем, у нас куча разных сервисов — базы, аналитика, мониторинг, CDN, бэкапы, виртуальные машинки и прочие вкусности. Мы возьмем их и аккуратненько разложим по полочкам.  

### Цель работы

- Понять, что делают разные азурные сервисы: от баз данных до аналитики, мониторинга и доставки контента.
- Научиться классифицировать этих ребят по категориям, подкатегориям.
- Распределить их по иерархии потребления.

### Дано

У нас есть здоровенная табличка, где перечислены сервисы Azure и то, как они тарифицируются. Категории (Database, Data & Analytics, Monitoring, Backup & Recovery, Networking, Compute), подкатегории (Relational Database, Business Analytics и т.д.), конкретные сервисы (например, Azure Database for MySQL, Azure Databricks, Azure Monitor…), и метрики (Compute Hours, Data Stored (GB), Notification Events, Data Transfer и прочие хитрые параметры).

### Необходимо

1. Загрузить данные в какую-нибудь табличку, чтобы было удобнее тыкать пальцем.  
2. Разложить все сервисы по категориям и понять их логику.  
3. Добавить описание каждого сервиса: кто он, что делает, зачем вообще нужна эта штука. 
4. Понять их единицы тарификации: за что мы платим — за время, объем, количество трансферов, активити рансы или что-то еще.  
5. Сохранить результаты в порядке убывания потребления.

### Алгоритм работы

1. Разделяем всю простыню по крупным веткам: Database, Data & Analytics, Monitoring, Backup & Recovery, Networking, Compute.  
2. Внутри каждой ветки смотрим подкатегории: например, в Analytics у нас Big Data & Analytics, Business Analytics, Caching, Real-time Analytics.  
3. Под каждую категорию запихиваем её сервисы.  
4. Даем каждому сервису характеристику чем он занимается.  
5. Смотрим, какими метриками измеряется его потребление (Compute Hours, Data Stored и т.д.).  
6. Запоминаем и сохраняем всё это добро, чтобы потом легче было анализировать.

### Ход работы

#### Database / Relational Database

- **Azure Database for MySQL / PostgreSQL (Single Server)**  
  Эти — классические реляционные базы. Хранение структурированных данных, SQL-запросики, удобный скейлинг.  
  Тарификация: DB Instance Hours — сколько часов работал твой инстанс, столько и плати.

#### Data & Analytics

*Big Data & Analytics:*  
- **Azure Databricks (Data Analytics, Data Engineering)**  
  Среда для больших данных и машинного обучения на базе Spark. Мгновение, и у тебя ETL, аналитика, тренировка моделей.  
  Платим в основном за Compute Hours (сколько часов нагружаем кластеры, столько и платим).

*Business Analytics:*  
- **Azure HDInsight (Compute Cluster)**  
  Управляемый Hadoop/Spark кластер. Гоним большие данные, распределенные вычисления.  
  Оплата: Compute Hours (мощность + время).
  
- **Azure Data Factory (Data Movement, Activity)**  
  Сервис для перетаскивания данных туда-сюда (Data Movement Cloud/On Premises), запуска ETL-процессов, трансформаций.  
  Оплата за Compute Hours, Data Movement Units или Activity Runs — зависит от того, что именно мы делаем: двигаем данные, крутим активити или что-то еще.

- **Azure Data Lake Store (Data at Rest, Transactions)**  
  Большое хранилище для твоих файлов. Холодное, теплое, какое угодно — просто складывай и храни.  
  Оплата за Data Stored (GB) и Transaction Count. Чем больше лежит и чем чаще дергаешь, тем дороже.

- **Azure Stream Analytics (Standard SU, Data Processed, Streaming Units)**  
  Потоковая аналитика: берешь данные "на лету" и сразу анализируешь.  
  Оплата: Compute Hours, Data Processed (GB), Streaming Units (Hours). Чем больше стримишь и жуешь данные, тем больше платишь.

*Caching:*  
- **Azure Redis Cache (Standard/Premium, C Series, C Variant)**  
  Ин-мемори кеш для ускорения всего и вся. Быстрый доступ, снижает нагрузку на основное хранилище.  
  Оплата: Cache Hours — сколько часов держим кеш, столько и чирикаем.

*Real-time Analytics:*  
- **Azure Stream Analytics (Streaming Units)**  
  Здесь тот же сервис, но уже отдельно упомянут. По сути, то же потоковое счастье, опять же Streaming Units (Hours).

#### Monitoring / Monitoring & Alerting

- **Azure Monitor (Notifications Webhook/Email)**  
  Сервис мониторинга и алертинга. Сматривает за состоянием ресурсов и шлет уведомления (вебхуки, email).  
  Оплата: Notification Events — чем больше ты спамишь себе уведомлений, тем больше платишь.

#### Backup & Recovery

- **Azure Backup (Geo Redundant Storage, Protected Instances)**  
  Бэкапы виртуалок и данных. Хранение резервных копий, чтобы потом нажать на кнопочку — и восстановить, если что-то пошло не так.  
  Оплата: Data Stored (GB) за объем хранилища и Protected Instances за каждую защищенную машинку.

#### Networking / Content Delivery Network

- **Azure CDN (Standard CDN, Data Transfer)**  
  Сервис доставки контента по миру. Картинки, видосики, статика — все летит к пользователям из ближайшей точки.  
  Оплата: Data Transfer (GB) — чем больше отдал, тем больше платишь.

#### Compute / Cloud Compute

- **Azure Batch (Reservation, License)**  
  Сервис для пакетных вычислений. Закинул кучу заданий, а Batch все сам порешает, масштабирует, управит.  
  Оплата: Compute Hours, License Hours — чем дольше крутим задачи, тем больше счет.

- **A/D/F/G/H/N-Series VMs**  
  Разные серии виртуалок для разных задач: CPU-интенсивные, GPU-тяжелые, для HPC, для базовых нагрузок.  
  Оплата: Compute Hours (или просто Compute) — все про время работы. Чем дольше держишь поднятую машину, тем больше она погрызет твой бюджет.

### Результаты обработки данных

После всей этой разборки стало ясно:

- Большая аналитика и вычисления (Databricks, HDInsight, VMs) — это Compute Hours.  
- Хранилища и бэкапы (Data Lake Store, Backup) — Data Stored (GB) и Transactions.  
- Потоки и движения данных (Data Factory, Stream Analytics) — там целый зоопарк юнитов, но тоже все вокруг объема и количества операций.  
- CDN — это про Data Transfer (GB).  
- Мониторинг — про количество уведомлений.  
- Базовые базы (круто сказал, да? :) ) — за Instance Hours.

### Распределяем все в порядке потребления и вот готовая табличка: [тыкай, друг, не бойся, я тебя не обижу](https://docs.google.com/spreadsheets/d/1rK44hvYy4a6Xv2l_UIceMkjFSLG5x6dKQWWrSIsKZUY/edit?usp=sharing)

### Вывод

В ходе этой лабы:

- Разобрали стопку азурных сервисов по понятным коробочкам.  
- Посмотрели, за что нас доят: Compute Hours, Data Stored, Events, Runs, Transfers — сколько фишек, столько вариантов.  
- Поняли, что каждый сервис особенный: кто-то грызет CPU часы, кто-то кушает гигабайты, кто-то шлет уведомления пачками.  
- Теперь можем чуть разумнее подходить к планированию бюджета и подкручивать ручки оптимизации.

Спасибо за внимание, тут шутки не будет.